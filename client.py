import asyncio
import os
import json
from datetime import datetime
import re
from openai import OpenAI
from dotenv import load_dotenv
from langchain.memory import ConversationBufferWindowMemory
from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from pymongo import MongoClient
import uuid
from typing import Optional
from contextlib import AsyncExitStack
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()


def safe_messages_to_dict(messages):
    result = []
    for m in messages:
        if isinstance(m, HumanMessage):
            result.append({"role": "user", "content": m.content})
        elif isinstance(m, AIMessage):
            result.append({"role": "assistant", "content": m.content})
        elif isinstance(m, SystemMessage):
            result.append({"role": "system", "content": m.content})
        else:
            print(f"[è­¦å‘Š] å¿½ç•¥æœªçŸ¥æ¶ˆæ¯ç±»å‹: {type(m)}")
    return result


class MCPClient:
    def __init__(self,server_script_path: str):
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = os.getenv("BASE_URL")
        self.model = os.getenv("MODEL")
        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)

        self.mongo_client = MongoClient(os.getenv("MONGO_URI", "mongodb://localhost:27017"))
        self.mongo_db = self.mongo_client["chat_memory_db"]
        self.collection_name = "mcp_memory"
        self.memory_id = str(uuid.uuid4())

        # âœ… æ–°ç”¨æ³•ï¼šlangchain_mongodb ä¸­çš„ MongoDBChatMessageHistory
        chat_history = MongoDBChatMessageHistory(
            session_id=self.memory_id,
            connection_string=os.getenv("MONGO_URI", "mongodb://localhost:27017"),
            database_name="chat_memory",
            collection_name=self.collection_name
        )

        self.memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            return_messages=True,
            chat_memory=chat_history,
            k=20,
        )

        self.session: Optional[ClientSession] = None
        self.server_script_path = server_script_path  # æ·»åŠ æœåŠ¡å™¨è·¯å¾„å‚æ•°

    async def __aenter__(self):
        await self.connect_to_server(self.server_script_path)
        return self

    async def __aexit__(self, *exc_info):
        await self.cleanup()

    async def connect_to_server(self, server_script_path: str):
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(command=command, args=[server_script_path], env=None)
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()

        response = await self.session.list_tools()
        tools = response.tools
        print("\nå·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in tools])

    async def process_query(self, query: str) -> str:
        response = await self.session.list_tools()
        available_tools = [
            {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                }
            } for tool in response.tools
        ]

        history_messages = self.memory.chat_memory.messages
        messages = safe_messages_to_dict(history_messages)

        if not messages:
            messages.append({"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"})

        messages.append({"role": "user", "content": query})

        print(f"\n[æŸ¥è¯¢] ç”¨æˆ·æŸ¥è¯¢: {query}")
        print(f"[å·¥å…·] å¯ç”¨å·¥å…·: {[tool['function']['name'] for tool in available_tools]}")

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=available_tools,
                tool_choice="auto"
            )

            assistant_message = response.choices[0].message
            messages.append({
                "role": "assistant",
                "content": assistant_message.content,
                "tool_calls": assistant_message.tool_calls
            })

            if assistant_message.tool_calls:
                print(f"\n[å·¥å…·è°ƒç”¨] æ¨¡å‹å†³å®šè°ƒç”¨ {len(assistant_message.tool_calls)} ä¸ªå·¥å…·")

                for tool_call in assistant_message.tool_calls:
                    tool_name = tool_call.function.name
                    try:
                        tool_args = json.loads(tool_call.function.arguments)
                    except json.JSONDecodeError:
                        tool_args = {}

                    print(f"[è°ƒç”¨] å·¥å…·åç§°: {tool_name}")
                    print(f"[å‚æ•°] {tool_args}")

                    try:
                        result = await self.session.call_tool(tool_name, tool_args)
                        tool_result = result.content[0].text if result.content else "å·¥å…·æ‰§è¡Œå®Œæˆ"

                        print(f"[æˆåŠŸ] å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")

                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": tool_result
                        })

                    except Exception as e:
                        print(f"[é”™è¯¯] å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}")
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                        })

                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages
                )
                final_output = final_response.choices[0].message.content
            else:
                final_output = assistant_message.content

        except Exception as e:
            print(f"[é”™è¯¯] å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            final_output = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {str(e)}"

        self.memory.chat_memory.add_user_message(query)
        self.memory.chat_memory.add_ai_message(final_output)

        self.save_conversation_log(query, final_output)

        return final_output

    def save_conversation_log(self, query: str, response: str):
        def clean_filename(text: str) -> str:
            text = text.strip()
            text = re.sub(r'[\\/:*?"<>|]', '', text)
            return text[:50]

        safe_filename = clean_filename(query)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{safe_filename}_{timestamp}.txt"
        output_dir = "./llm_outputs"
        os.makedirs(output_dir, exist_ok=True)
        file_path = os.path.join(output_dir, filename)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"ğŸ—£ ç”¨æˆ·æé—®ï¼š{query}\n\n")
            f.write(f"ğŸ¤– æ¨¡å‹å›å¤ï¼š\n{response}\n")

        print(f"ğŸ“„ å¯¹è¯è®°å½•å·²ä¿å­˜ä¸ºï¼š{file_path}")

    async def chat_loop(self):
        print("\n[å¯åŠ¨] MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
        print("[æç¤º] ä½ å¯ä»¥å°è¯•ä»¥ä¸‹å‘½ä»¤ï¼š")
        print("   - æœç´¢å°ç±³æ±½è½¦çš„æ–°é—»")
        print("   - åˆ†æä¸€ä¸‹è¿™æ®µæ–‡å­—çš„æƒ…æ„Ÿï¼š[ä½ çš„æ–‡å­—]")
        print("   - æŸ¥è¯¢æ•°æ®åº“ä¸­çš„é¢„çº¦è®°å½•")
        print("   - ä¿®æ”¹ç”¨æˆ·å¼ ä¸‰çš„é¢„çº¦æ—¶é—´ä¸ºæ˜å¤©ä¸‹åˆ2ç‚¹")
        print("   - å‘é€é‚®ä»¶åˆ° example@email.com")
        print("   - æœç´¢å…³äºåŒ—äº¬åå’ŒåŒ»é™¢çš„ä¿¡æ¯")
        print("   - æ¸…ç†æ–‡ä»¶å¤¹æ–‡ä»¶")

        while True:
            try:
                query = input("\nä½ : ").strip()
                if query.lower() == 'quit':
                    break

                if not query:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢å†…å®¹")
                    continue

                response = await self.process_query(query)
                print(f"\n[AIå›å¤] {response}")

            except KeyboardInterrupt:
                print("\n[é€€å‡º] ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        await self.exit_stack.aclose()
async def main():
    server_script_path = "D:\\PythonProject\\mcp-project\\server.py"
    client = MCPClient()
    try:
        await client.connect_to_server(server_script_path)
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())


